{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 10: Evaluating our Gesture Recognition NNs ðŸ•¸"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name: Mahoto Sasaki\n",
    "\n",
    "Student ID: 467695\n",
    "\n",
    "Collaborators:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "\n",
    "In our _last_ homework (woohoo!), we will be analyzing and evaluating the gesture recognition data and models created in `Lab10`. This is a great opportunity to recap the **Data Science workflow** with all its major aspects: \n",
    "\n",
    "- exploratory data analysis (EDA) and data profiling\n",
    "- machine learning workkflow\n",
    "- training, validation, testing data\n",
    "- model comparison\n",
    "- presenting results (creating plot)\n",
    "\n",
    "It will be extremely helpful to review **Lab 10 (Gesture Recognition with Neural Networks)** first.\n",
    "\n",
    "In general, you should feel free to import any package that we have previously used in class. Ensure that all plots have the necessary components that a plot should have (e.g. axes labels, a title, a legend).\n",
    "\n",
    "Furthermore, in addition to recording your collaborators on this homework, please also remember to cite/indicate all external sources used when finishing this assignment. This includes peers, TAs, and links to online sources. Note that these citations will not free you from your obligation to submit your _own_ code and write-ups, however, they will be taken into account during the grading and regrading process.\n",
    "\n",
    "### Submission instructions\n",
    "* Submit this python notebook including your answers in the code cells as homework submission.\n",
    "* **Feel free to add as many cells as you need to** â€” just make sure you don't change what we gave you. \n",
    "* **Does it spark joy?** Note that you will be partially graded on the presentation (_cleanliness, clarity, comments_) of your notebook so make sure you [Marie Kondo](https://lifehacker.com/marie-kondo-is-not-a-verb-1833373654) your notebook before submitting it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "\n",
    "The data needed for this assignemnt can be found [here](https://wustl.box.com/s/q8mnl1o2zq2bh0ca5zajtk3msnu03ou8). All of it was gathered in `Homework 10 (Part I)`: \n",
    "- training\n",
    "- validation\n",
    "- augmented\n",
    "- testing\n",
    "\n",
    "Here are the neural network models trained on `training`:\n",
    "- cse217_v1.h5 (still training; watch for announcement on Piazza)\n",
    "- cse217_v2.h5 (still training; watch for announcement on Piazza)\n",
    "\n",
    "Here are the neural network models trained on `augmented`:\n",
    "- cse217_v1_augmented.h5 (still training; watch for announcement on Piazza)\n",
    "- cse217_v2_augmented.h5 (still training; watch for announcement on Piazza)\n",
    "\n",
    "Note that to train these models we used the `validation` dataset to determine when to stop the training process. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Test Data Collection, Data Profiling, and Model Understanding\n",
    "\n",
    "In this section, we will get a feel for our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 0\n",
    "\n",
    "Following the instructions in `Lab10_DataAquisition` take 15 images of rock, paper, and scissors gestures (cf. `1.1 How To Take The Pictures`) and scale them using the provided code (`1.2 Storing, Scaling, and Sharing the Images`). Store them in a folder called `testing` along with the already collected data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import makedirs, mkdir\n",
    "from os.path import exists\n",
    "\n",
    "base = 'utility/data'\n",
    "raw = f'{base}/raw'\n",
    "dirs = ['rock', 'paper', 'scissors']\n",
    "\n",
    "if not exists(raw):\n",
    "    makedirs(raw, exist_ok=True)\n",
    "\n",
    "for sign in dirs:\n",
    "    path = f'{raw}/{sign}'\n",
    "    \n",
    "    if not exists(path):\n",
    "        mkdir(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Try this!** Store the images you took of rocks (âœŠ), papers (ðŸ¤š), and scissors (âœŒï¸) in the correct folders in `utility/data/raw`. Then, run the following cell to produced rescaled images, which will be stored in `utility/data/testing`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "from utility.util import load_image, resize_image, save_image\n",
    "\n",
    "\n",
    "testing = f'{base}/testing'\n",
    "\n",
    "for sign in dirs:\n",
    "    path = f'{testing}/{sign}'\n",
    "    \n",
    "    if not exists(path):\n",
    "        makedirs(path, exist_ok=True)\n",
    "\n",
    "for path, _, files in os.walk(raw):\n",
    "    sign = os.path.basename(path)\n",
    "\n",
    "    for file in files:\n",
    "        input_path = f'{path}/{file}'\n",
    "        output_path = f'{testing}/{sign}/{file}'\n",
    "        \n",
    "        # note! warnings about lossy conversion are ok\n",
    "        image = load_image(input_path)\n",
    "        image = resize_image(image, (500, 500))\n",
    "\n",
    "        save_image(output_path, image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1\n",
    "\n",
    "**Write-up!**  Report the number of images per class in each of the four datasets. Are the dataset balanced? No code submission required.\n",
    "> Hint: For most of this you can use the code from `Lab10_Model` with light modifications. "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "| training | validation | testing | augmented\n",
    "        rock (c0) |\n",
    "       paper (c1) |        \n",
    "    scissors (c2) |   \n",
    "\n",
    "\n",
    "# your response here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2\n",
    "Now, let's look at our models. \n",
    "\n",
    "**Write-up!**  Compare the following statistics for all four models: \n",
    "- number of parameters\n",
    "- number of convolutional layers\n",
    "- number of dense layers\n",
    "- size of the model (`.h5`) file \n",
    "\n",
    "What are the most surprising aspects of these statistics to you? "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "| # parameters | # conv layers | # dense layers | file size\n",
    "            cse217_v1 |\n",
    "            cse217_v2 |        \n",
    "  cse217_v1_augmented |   \n",
    "  cse217_v2_augmented |   \n",
    "\n",
    "\n",
    "# your response here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Comparison: v1 vs v2\n",
    "\n",
    "By now we should know all of the ins and outs about our datasets and models (right?). Let's evaluate and compare the models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3\n",
    "\n",
    "First let's investiage which of the two versions `cse217_v1` or `cse217_v2` performs better in the non-augmented setting. You can use the code provided in the *updated version* of  `Lab10_Model` under `5. Evaluate Neural Network on Validation Data` with light modifications. \n",
    "\n",
    "**Write-up** For both versions report the accuracy on all three datasets `training`, `validation`, and `testing` and summarize your findings. \n",
    "- Which model performs better? Justify your answer based on the presented accuraccies. \n",
    "- Argue whether we can be happy with the perfomrance of our model. If yes, justify why, if no, give suggestions on how to imporve the performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cell, we provide an example of how to load the testing. Note the dimensions of the dataset (especially the size of the images)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utility.util import load_dataset\n",
    "\n",
    "target_shape = (500, 500)\n",
    "X_test_example, y_test_example = load_dataset('utility/data/testing', target_shape)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "| training acc | validation acc | testing acc \n",
    "    cse217_v1 |\n",
    "    cse217_v2 | \n",
    "\n",
    "# your response here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4\n",
    "\n",
    "Now, that we have summarized and analyzed the average performance of the models, let's look at individual images. \n",
    "\n",
    "**Write-up**  Using your own `testing` set and the better performing version that you identified in the previous problem, which of the three classes get predicted more correctly, which of the classes get mistaken for what other classes more frequently? \n",
    "\n",
    "> Hint: you may use the visualization implemented in the *updated version* of  `Lab10_Model` under `5. Evaluate Neural Network on Validation Data` (last code cell).  "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# your response here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Comparison: original vs augmented\n",
    "\n",
    "Now, let's investiage whether data augmentation imporves performance. \n",
    "\n",
    "\n",
    "### Problem 5\n",
    "\n",
    "Which of the models `cse217_vx`  or `cse217_vx_augmented` for both versions performs better? You can again use the code provided in the *updated version* of `Lab10_Model` under `5. Evaluate Neural Network on Validation Data` with light modifications. \n",
    "\n",
    "**Write-up** Report and compare the accuracy on all three datasets `training`, `validation`, and `testing` of the original and the augmented model for both versions. Summarize your findings. \n",
    "- Did data augemntation help? \n",
    "- Which of the two NN versions benefited or suffered more from data augmentation? \n",
    "- Give an explanation/guestimate why this is the case."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "| training acc | validation acc | testing acc \n",
    "            cse217_v1 |\n",
    "  cse217_v1_augmented | \n",
    "  \n",
    "  \n",
    "                      | training acc | validation acc | testing acc \n",
    "            cse217_v2 |\n",
    "  cse217_v2_augmented | \n",
    "\n",
    "# your response here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 6\n",
    "\n",
    "Now, let's have some fun! \n",
    "\n",
    "Let's explore a _real-time_ version of the model you identified as performing best running with your webcam. Open a new terminal window (on Mac OS you will need to use the built-in terminal app) and navigate to the directory, where you stored the model. Once there, run the following command, substituting `<model_name>` for the name of the file containing your model:\n",
    "\n",
    "```\n",
    "$ python(3) realtime.py <model_name>\n",
    "```\n",
    "\n",
    "Have fun!\n",
    "\n",
    "Note, `realtime.py` uses opencv, so you miht need to install it: \n",
    "\n",
    "- **opencv**: `pip(3) install opencv-python`\n",
    "\n",
    "\n",
    "**Write-up**  Summarize the performance of our NN model. \n",
    "- When does it work well, when does it have difficulties in predicting the correct gesture? Consider angle, background, and distance in your answer.  \n",
    "- Which of the three classes get predicted more correctly, which of the classes get mistaken for what other classes more frequently? "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# your response here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that's it! Remember to review your work and make sure it is well presented and organized. Not everyting you coded up needs to remain in your submission, infact for this hw, we arenot expecting any code submission. **[Does [this cell] spark joy?](https://i.kinja-img.com/gawker-media/image/upload/s--iW_3HGbT--/c_scale,dpr_2.0,f_auto,fl_progressive,q_80,w_800/oruf4oavtj5vpmvaquew.jpg)** You are always trying to communicate your findings to somebody, _maybe even yourself_."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
